{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a008c2eb-7fac-4784-807c-7119a1a84188",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5844a3af-048a-4579-8a64-5e7ef630f800",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install faker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e316d1ba-aa89-4bb7-9493-a8443b000461",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d412762-c888-4670-acc5-40398b683b62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Parâmetros de Configuração\n",
    "\n",
    "- **NOME_APLICACAO_SPARK**: Nome identificador desta execução no ambiente Spark.\n",
    "- **ANO_ESTATISTICA**: Ano base utilizado para buscar as estatísticas de volume de transações.\n",
    "- **FATOR_ESCALA_VOLUME**: Fator de escala para reduzir o volume total de transações geradas. Por exemplo, `0.006` indica que será gerado apenas 0,6% do volume real, útil para criar amostras menores e mais rápidas de processar.\n",
    "- **LIMITE_ABSOLUTO_TX**: Limite máximo absoluto de transações a serem geradas, evitando volumes excessivos.\n",
    "- **LIMITE_MUNICIPIOS_PROCESSADOS**: Quantidade máxima de municípios para os quais serão gerados dados, priorizando aqueles com maior volume.\n",
    "- **PROBABILIDADE_TRANSACAO_INTERMUNICIPAL**: Proporção de transações que terão como destino um município diferente do de origem (ex: 20%), tornando a simulação mais realista.\n",
    "\n",
    "---\n",
    "\n",
    "### Parâmetros de Fraude\n",
    "\n",
    "- **PROBABILIDADE_FRAUDE_BASE**: Probabilidade padrão de uma transação ser fraudulenta (ex: 5%).\n",
    "- **PROB_CONTA_ALTO_RISCO**: Probabilidade de uma conta ser classificada como \"alto risco\" ao ser criada (ex: 10%).\n",
    "- **PROBABILIDADE_FRAUDE_CONTA_DESTINO_RISCO**: Probabilidade de fraude quando o destino é uma conta de alto risco (ex: 60%).\n",
    "- **PROBABILIDADE_FRAUDE_CHAVE_RECENTE**: Probabilidade de fraude quando o PIX é destinado a uma chave recém-cadastrada (ex: 40%), já que contas novas são frequentemente usadas em golpes.\n",
    "- **DIAS_CHAVE_CONSIDERADA_RECENTE**: Número de dias para considerar uma chave como \"recente\" (ex: 7 dias).\n",
    "- **MAX_DIAS_CADASTRO_CHAVE_RISCO**: Prazo máximo para contas de alto risco cadastrarem suas chaves PIX após a abertura (ex: 5 dias).\n",
    "\n",
    "---\n",
    "\n",
    "### Parâmetros Gerais\n",
    "\n",
    "- **MULTIPLICADOR_MAGNITUDE_OUTLIER**: Multiplicador para definir o valor de uma transação \"outlier\" (ex: 25 vezes o valor base).\n",
    "- **MULTIPLICADOR_MAGNITUDE_FRAUDE**: Multiplicador para definir o valor de uma transação fraudulenta (ex: 50 vezes o valor base), simulando tentativas de golpes de alto valor.\n",
    "- **PROBABILIDADES_TIPO_FRAUDE**: Dicionário que define a chance de cada tipo de fraude ocorrer. Exemplo: `valor_atipico` tem 30% de chance de ser o tipo escolhido em caso de fraude.\n",
    "- **PESO_CONTAS_POS_PIX**: Proporção de contas criadas após o lançamento do PIX (ex: 70%), refletindo o aumento da bancarização no período."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55ad0bfd-3b2c-49a8-b619-aa39da66a56e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 1: CONFIGURAÇÃO DE PARÂMETROS GLOBAIS (VERSÃO FINAL)\n",
    "# =============================================================================\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, DateType, DoubleType, IntegerType, TimestampType\n",
    ")\n",
    "from faker import Faker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import uuid\n",
    "from datetime import timedelta, datetime\n",
    "import calendar\n",
    "from typing import Iterator\n",
    "import functools\n",
    "\n",
    "print(\"INFO: Definindo parâmetros globais para treinamento de IA (com estratégias avançadas)...\")\n",
    "\n",
    "# === PARÂMETROS DE ESCALA E VOLUME ===\n",
    "ANO_ESTATISTICA = 2023\n",
    "LIMITE_MUNICIPIOS_PROCESSADOS = 15 \n",
    "FATOR_ESCALA_VOLUME = 0.00005 \n",
    "TX_POR_CLIENTE_ESPERADO = 10.0 \n",
    "PROBABILIDADE_TRANSACAO_INTERMUNICIPAL = 0.20 \n",
    "\n",
    "# === PARÂMETROS DE RISCO E CONTA ===\n",
    "PROB_CONTA_ALTO_RISCO = 0.03 \n",
    "PESO_CONTAS_POS_PIX = 0.70 \n",
    "\n",
    "# === PARÂMETROS DE FRAUDE (REALISTAS) ===\n",
    "PROBABILIDADE_FRAUDE_BASE = 0.005 # (0.5%)\n",
    "PROBABILIDADE_FRAUDE_CONTA_DESTINO_RISCO = 0.60 \n",
    "PROBABILIDADE_FRAUDE_CHAVE_RECENTE = 0.40      \n",
    "MULTIPLICADOR_MAGNITUDE_FRAUDE = 30 \n",
    "DIAS_CHAVE_CONSIDERADA_RECENTE = 7            \n",
    "MAX_DIAS_CADASTRO_CHAVE_RISCO = 5 \n",
    "\n",
    "PROBABILIDADES_TIPO_FRAUDE = {\n",
    "    \"valor_atipico\": 0.30, \"engenharia_social\": 0.25, \"tomada_de_conta\": 0.15, \n",
    "    \"triangulacao_conta_laranja\": 0.15, \"fraude_qr_code\": 0.10, \"ataque_de_frequencia\": 0.05\n",
    "}\n",
    "\n",
    "# === PARÂMETROS DE ESTRATÉGIAS AVANÇADAS DE FRAUDE ===\n",
    "PROBABILIDADE_ATAQUE_MADRUGADA = 0.70 \n",
    "PROBABILIDADE_TESTE_CONTA = 0.30\n",
    "PROBABILIDADE_ABAIXO_RADAR = 0.40\n",
    "VALORES_LIMITE_RADAR = [499.90, 999.90, 1999.90, 4999.90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c098b61a-0d3b-4791-8acc-95c85081808b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Inicialização do Ambiente e Esquemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d762d55c-9a11-44a3-9ec2-ff5e2af59c21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 2: SETUP DO SPARK E DEFINIÇÃO DE SCHEMAS\n",
    "# =============================================================================\n",
    "NOME_APLICACAO_SPARK = \"GeradorDadosPix_Final_v12.0_Otimizado\"\n",
    "\n",
    "fake = Faker('pt_BR')\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "spark = SparkSession.builder.appName(NOME_APLICACAO_SPARK).getOrCreate()\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"200\")\n",
    "\n",
    "print(\"INFO: Definindo esquemas explícitos para UDFs e tabelas Delta...\")\n",
    "\n",
    "SCHEMA_PARES = StructType([\n",
    "    StructField(\"id_conta_origem\", StringType(), True),\n",
    "    StructField(\"id_conta_destino\", StringType(), True)\n",
    "])\n",
    "\n",
    "SCHEMA_CLIENTES_UDF = StructType([\n",
    "    StructField(\"nome\", StringType()),\n",
    "    StructField(\"registro_nacional\", StringType()),\n",
    "    StructField(\"nascido_em\", DateType())\n",
    "])\n",
    "\n",
    "SCHEMA_CONTAS_UDF = StructType([\n",
    "    StructField(\"id\", StringType()),\n",
    "    StructField(\"saldo\", DoubleType()),\n",
    "    StructField(\"aberta_em\", DateType()),\n",
    "    StructField(\"agencia\", StringType()),\n",
    "    StructField(\"numero\", StringType()),\n",
    "    StructField(\"id_tipo_conta\", IntegerType()),\n",
    "    StructField(\"ispb_instituicao\", StringType()),\n",
    "    StructField(\"id_cliente\", StringType()),\n",
    "    StructField(\"is_high_risk\", IntegerType())\n",
    "])\n",
    "\n",
    "SCHEMA_CHAVES_UDF = StructType([\n",
    "    StructField(\"id\", StringType()),\n",
    "    StructField(\"chave\", StringType()),\n",
    "    StructField(\"id_tipo_chave\", IntegerType()),\n",
    "    StructField(\"cadastrada_em\", DateType()),\n",
    "    StructField(\"id_conta\", StringType())\n",
    "])\n",
    "\n",
    "SCHEMA_TRANSACOES_UDF = StructType([\n",
    "    StructField(\"id\", StringType()),\n",
    "    StructField(\"valor\", DoubleType()),\n",
    "    StructField(\"data\", TimestampType()),\n",
    "    StructField(\"mensagem\", StringType()),\n",
    "    StructField(\"id_conta_origem\", StringType()),\n",
    "    StructField(\"id_conta_destino\", StringType()),\n",
    "    StructField(\"id_tipo_iniciacao_pix\", IntegerType()),\n",
    "    StructField(\"id_finalidade_pix\", IntegerType()),\n",
    "    StructField(\"is_fraud\", IntegerType()),\n",
    "    StructField(\"fraud_type\", StringType()),\n",
    "    StructField(\"id_transacao_cadeia_pai\", StringType())\n",
    "])\n",
    "\n",
    "SCHEMA_CLIENTES_FINAL = StructType([\n",
    "    StructField(\"id\", StringType(), False),\n",
    "    StructField(\"nome\", StringType()),\n",
    "    StructField(\"id_natureza\", IntegerType()),\n",
    "    StructField(\"registro_nacional\", StringType()),\n",
    "    StructField(\"nascido_em\", DateType()),\n",
    "    StructField(\"estado_ibge\", IntegerType()),\n",
    "    StructField(\"municipio_ibge\", IntegerType())\n",
    "])\n",
    "\n",
    "SCHEMA_CONTAS_FINAL = StructType(\n",
    "    SCHEMA_CONTAS_UDF.fields + [\n",
    "        StructField(\"estado_ibge\", IntegerType()),\n",
    "        StructField(\"municipio_ibge\", IntegerType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "SCHEMA_CHAVES_PIX_FINAL = StructType(\n",
    "    SCHEMA_CHAVES_UDF.fields + [\n",
    "        StructField(\"estado_ibge\", IntegerType()),\n",
    "        StructField(\"municipio_ibge\", IntegerType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "SCHEMA_TRANSACOES_FINAL = StructType(\n",
    "    SCHEMA_TRANSACOES_UDF.fields + [\n",
    "        StructField(\"estado_ibge\", IntegerType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "config_geracao = {\n",
    "    \"PROBABILIDADE_FRAUDE_BASE\": PROBABILIDADE_FRAUDE_BASE,\n",
    "    \"PROB_CONTA_ALTO_RISCO\": PROB_CONTA_ALTO_RISCO,\n",
    "    \"PROBABILIDADE_FRAUDE_CONTA_DESTINO_RISCO\": PROBABILIDADE_FRAUDE_CONTA_DESTINO_RISCO,\n",
    "    \"PROBABILIDADE_FRAUDE_CHAVE_RECENTE\": PROBABILIDADE_FRAUDE_CHAVE_RECENTE,\n",
    "    \"DIAS_CHAVE_CONSIDERADA_RECENTE\": DIAS_CHAVE_CONSIDERADA_RECENTE,\n",
    "    \"MAX_DIAS_CADASTRO_CHAVE_RISCO\": MAX_DIAS_CADASTRO_CHAVE_RISCO,\n",
    "    \"MULTIPLICADOR_MAGNITUDE_FRAUDE\": MULTIPLICADOR_MAGNITUDE_FRAUDE,\n",
    "    \"PROBABILIDADES_TIPO_FRAUDE\": PROBABILIDADES_TIPO_FRAUDE,\n",
    "    \"PESO_CONTAS_POS_PIX\": PESO_CONTAS_POS_PIX,\n",
    "    \n",
    "    # Adição dos novos parâmetros de estratégia\n",
    "    \"PROBABILIDADE_ATAQUE_MADRUGADA\": PROBABILIDADE_ATAQUE_MADRUGADA,\n",
    "    \"PROBABILIDADE_TESTE_CONTA\": PROBABILIDADE_TESTE_CONTA,\n",
    "    \"PROBABILIDADE_ABAIXO_RADAR\": PROBABILIDADE_ABAIXO_RADAR,\n",
    "    \"VALORES_LIMITE_RADAR\": VALORES_LIMITE_RADAR}\n",
    "\n",
    "print(\"INFO: Carregando dados de dimensão e estatísticas...\")\n",
    "try:\n",
    "    instituicoes_pd = spark.table(\"transacoes_db.copper.instituicoes\").toPandas()\n",
    "    tipos_conta_pd = spark.table(\"transacoes_db.copper.tipos_conta\").toPandas()\n",
    "    perfis_de_uso_dict = spark.table(\"transacoes_db.pix_baseline_metricas.perfil_de_usuarios\").toPandas().to_dict('records')\n",
    "    LISTA_ISPBS_LOCAL = instituicoes_pd['ispb'].tolist()\n",
    "    LISTA_TIPOS_CONTA_LOCAL = tipos_conta_pd['id'].tolist()\n",
    "    print(\"INFO: Dados auxiliares e estatísticas carregados com sucesso.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERRO: Falha ao carregar dados de dimensão ou estatísticas. Erro: {e}\"); raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5b8147d-718b-41bc-8b76-8743167c9aa7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TABLE transacoes_db.pix_baseline_metricas.volumes_anuais_por_municipio\n",
    "COMMENT 'Tabela agregada com os volumes totais anuais por município para acelerar o pipeline de geração de dados.'\n",
    "AS\n",
    "SELECT\n",
    "  ano AS Ano,\n",
    "  Municipio_Ibge AS cod_ibge_municipio,\n",
    "  Municipio AS municipio_nome,\n",
    "  \n",
    "  -- ALTERAÇÃO APLICADA AQUI: Derivando o código do estado a partir do código do município\n",
    "  CAST(SUBSTRING(CAST(Municipio_Ibge AS STRING), 1, 2) AS INT) AS cod_ibge_estado,\n",
    "  \n",
    "  -- Calculando o total de transações de pagadores\n",
    "  SUM(total_tx_pf_pagador + total_tx_pj_pagador) AS volume_pagador_anual,\n",
    "  \n",
    "  -- Mantendo os nomes das colunas de origem para o cálculo do número de clientes\n",
    "  SUM(total_tx_pf_pagador) AS total_pf_anual,\n",
    "  SUM(total_tx_pj_pagador) AS total_pj_anual\n",
    "FROM\n",
    "  transacoes_db.pix_baseline_metricas.relacao_pagadores_recebedores\n",
    "GROUP BY\n",
    "  ano,\n",
    "  Municipio_Ibge,\n",
    "  Municipio,\n",
    "  -- Agrupando também pela coluna derivada\n",
    "  CAST(SUBSTRING(CAST(Municipio_Ibge AS STRING), 1, 2) AS INT);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe155e97-b861-451c-90f6-c6ebc3a72eea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "OPTIMIZE transacoes_db.pix_baseline_metricas.relacao_pagadores_recebedores;\n",
    "\n",
    "\n",
    "OPTIMIZE transacoes_db.pix_baseline_metricas.relacao_pagadores_recebedores\n",
    "ZORDER BY (ano, Municipio_Ibge);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c7511c2-b2cb-4d6b-843c-22ae96a527c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Funções de Geração e Salvamento\n",
    "\n",
    "As funções abaixo trabalham em conjunto para criar a população e as transações de um município:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. `_gerar_clientes`, `_gerar_contas`, `_gerar_chaves_pix`\n",
    "\n",
    "- **_gerar_clientes**  \n",
    "  Cria o número especificado de Pessoas Físicas (PF) e Jurídicas (PJ), gerando IDs, nomes, CPFs/CNPJs e datas de nascimento/fundação.\n",
    "\n",
    "- **_gerar_contas**  \n",
    "  Para cada cliente, cria um número aleatório de contas bancárias.\n",
    "\n",
    "- **_gerar_chaves_pix**  \n",
    "  Para cada conta, gera uma chave PIX (CPF, e-mail, telefone, etc.), garantindo que a data de cadastro da chave seja sempre posterior à data de abertura da conta.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. `_gerar_detalhes_transacao_python_vetorizado`\n",
    "\n",
    "Função responsável por criar os detalhes de cada transação:\n",
    "\n",
    "- **Data da Transação:**  \n",
    "  Seleciona uma data e hora aleatória dentro do mês de referência.\n",
    "\n",
    "- **Lógica de Fraude:**  \n",
    "  Define a probabilidade de fraude com base em regras, como se a conta destino é de risco ou se a chave é recente.\n",
    "\n",
    "- **Valor por Tipo de Conta:**  \n",
    "  Gera um valor monetário condizente com o tipo de transação (ex: salário, transferência para poupança, etc.).\n",
    "\n",
    "- **Multiplicadores de Fraude e Outlier:**  \n",
    "  Aumenta drasticamente o valor da transação se ela for fraudulenta ou um outlier.\n",
    "\n",
    "- **Fraudes em Cadeia:**  \n",
    "  Para certos tipos de fraude, divide o valor inicial em várias subtransações menores, simulando lavagem de dinheiro.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. `gerar_transacoes`\n",
    "\n",
    "Orquestra a geração das transações para um município em um determinado mês:\n",
    "\n",
    "- **Divisão do Volume:**  \n",
    "  Separa o total de transações em locais e intermunicipais.\n",
    "\n",
    "- **Geração de Pares Locais:**  \n",
    "  Sorteia aleatoriamente pares de contas (origem e destino) do mesmo município.\n",
    "\n",
    "- **Geração de Pares Intermunicipais:**  \n",
    "  Sorteia contas de origem do município atual e contas de destino de outros municípios.\n",
    "\n",
    "- **União e Enriquecimento:**  \n",
    "  Junta os dois conjuntos de pares e busca as informações necessárias para gerar os detalhes de cada transação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d31bc5ee-a950-4064-8ec2-d688a095b1a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 3: FUNÇÕES DE GERAÇÃO DE DADOS (VERSÃO FINAL COMPLETA)\n",
    "# =============================================================================\n",
    "\n",
    "# --- Funções de Geração de População ---\n",
    "\n",
    "@F.pandas_udf(SCHEMA_CLIENTES_UDF)\n",
    "def _gerar_detalhes_cliente_udf(id_natureza: pd.Series) -> pd.DataFrame:\n",
    "    local_fake = Faker('pt_BR')\n",
    "    n = len(id_natureza)\n",
    "    nomes_pf = [local_fake.name() for _ in range(n)]; nomes_pj = [local_fake.company() for _ in range(n)]\n",
    "    nomes = np.where(id_natureza == 1, nomes_pf, nomes_pj)\n",
    "    registros_pf = [local_fake.cpf() for _ in range(n)]; registros_pj = [local_fake.cnpj() for _ in range(n)]\n",
    "    registros = np.where(id_natureza == 1, registros_pf, registros_pj)\n",
    "    nascimentos = [\n",
    "        local_fake.date_of_birth(minimum_age=18, maximum_age=80) if nat == 1 \n",
    "        else local_fake.date_between(start_date='-20y', end_date='-1y')\n",
    "        for nat in id_natureza\n",
    "    ]\n",
    "    return pd.DataFrame({\"nome\": nomes, \"registro_nacional\": registros, \"nascido_em\": nascimentos})\n",
    "\n",
    "def _gerar_clientes(num_pf: int, num_pj: int, estado_ibge: int, municipio_ibge: int) -> DataFrame:\n",
    "    df_base_pf = spark.range(num_pf).withColumn(\"id_natureza\", F.lit(1)); df_base_pj = spark.range(num_pj).withColumn(\"id_natureza\", F.lit(2))\n",
    "    df_base_clientes = df_base_pf.union(df_base_pj)\n",
    "    return (df_base_clientes.withColumn(\"id\", F.expr(\"uuid()\"))\n",
    "        .withColumn(\"detalhes\", _gerar_detalhes_cliente_udf(F.col(\"id_natureza\")))\n",
    "        .select(\"id\", F.col(\"detalhes.nome\").alias(\"nome\"), \"id_natureza\",\n",
    "                F.col(\"detalhes.registro_nacional\").alias(\"registro_nacional\"),\n",
    "                F.col(\"detalhes.nascido_em\").alias(\"nascido_em\"),\n",
    "                F.lit(estado_ibge).alias(\"estado_ibge\"), F.lit(municipio_ibge).alias(\"municipio_ibge\")))\n",
    "\n",
    "def _gerar_detalhes_conta_python(iterator: Iterator[pd.DataFrame], config: dict, tipos_conta: list, ispbs: list, ano_estatistica: int) -> Iterator[pd.DataFrame]:\n",
    "    local_fake = Faker('pt_BR'); data_limite_abertura = datetime(ano_estatistica, 1, 1).date()\n",
    "    for lote in iterator:\n",
    "        resultados = []\n",
    "        for row in lote.itertuples(index=False):\n",
    "            is_high_risk = 1 if random.random() < config['PROB_CONTA_ALTO_RISCO'] else 0\n",
    "            if is_high_risk == 1:\n",
    "                start_date_relativa = timedelta(days=180); data_inicio_recente = data_limite_abertura - start_date_relativa\n",
    "                aberta_em = local_fake.date_between(start_date=data_inicio_recente, end_date=data_limite_abertura)\n",
    "            else: aberta_em = local_fake.date_between(start_date='-10y', end_date=data_limite_abertura)\n",
    "            if row.id_natureza == 1: saldo = round(np.random.lognormal(mean=6, sigma=1.5), 2); tipo_conta = random.choice(tipos_conta)\n",
    "            else: saldo = round(np.random.lognormal(mean=9, sigma=1.8), 2); tipo_conta = random.choice([c for c in tipos_conta if c in [1, 3]])\n",
    "            resultados.append({\"id\": str(uuid.uuid4()), \"saldo\": saldo, \"aberta_em\": aberta_em, \"agencia\": local_fake.numerify('####'), \n",
    "                               \"numero\": local_fake.numerify('#####-#'), \"id_tipo_conta\": tipo_conta, \"ispb_instituicao\": random.choice(ispbs),\n",
    "                               \"id_cliente\": row.id_cliente, \"is_high_risk\": is_high_risk})\n",
    "        yield pd.DataFrame(resultados)\n",
    "\n",
    "def _gerar_contas(df_clientes: DataFrame, estado_ibge: int, municipio_ibge: int) -> DataFrame:\n",
    "    df_clientes_com_num_contas = df_clientes.withColumn(\"num_contas\", F.when(F.col(\"id_natureza\") == 1, F.floor(F.rand() * 2) + 1).otherwise(F.floor(F.rand() * 5) + 1))\n",
    "    df_contas_base = df_clientes_com_num_contas.select(F.col(\"id\").alias(\"id_cliente\"), \"id_natureza\", F.explode(F.sequence(F.lit(1), F.col(\"num_contas\"))))\n",
    "    gerador_com_contexto = functools.partial(_gerar_detalhes_conta_python, config=config_geracao, tipos_conta=LISTA_TIPOS_CONTA_LOCAL, ispbs=LISTA_ISPBS_LOCAL, ano_estatistica=ANO_ESTATISTICA)\n",
    "    return (df_contas_base.mapInPandas(gerador_com_contexto, schema=SCHEMA_CONTAS_UDF)\n",
    "            .withColumn(\"estado_ibge\", F.lit(estado_ibge)).withColumn(\"municipio_ibge\", F.lit(municipio_ibge)))\n",
    "\n",
    "def _gerar_detalhes_chave_udf(iterator: Iterator[pd.DataFrame], config: dict) -> Iterator[pd.DataFrame]:\n",
    "    local_fake = Faker('pt_BR')\n",
    "    for lote in iterator:\n",
    "        resultados = [];\n",
    "        for row in lote.itertuples(index=False):\n",
    "            try:\n",
    "                data_abertura_obj = pd.to_datetime(row.aberta_em).date()\n",
    "                dias_para_cadastrar = random.randint(1, config['MAX_DIAS_CADASTRO_CHAVE_RISCO']) if hasattr(row, 'is_high_risk') and row.is_high_risk == 1 else random.randint(1, 90)\n",
    "                cadastrada_em = data_abertura_obj + timedelta(days=dias_para_cadastrar)\n",
    "                tipos_possiveis = {1: row.registro_nacional, 2: local_fake.email(), 3: local_fake.phone_number(), 4: str(uuid.uuid4())} if row.id_natureza == 1 else {5: row.registro_nacional, 2: local_fake.company_email(), 4: str(uuid.uuid4())}\n",
    "                tipo_chave = random.choice(list(tipos_possiveis.keys()))\n",
    "                resultados.append({\"id\": str(uuid.uuid4()), \"chave\": tipos_possiveis[tipo_chave], \"id_tipo_chave\": tipo_chave, \"cadastrada_em\": cadastrada_em, \"id_conta\": row.id_conta})\n",
    "            except Exception as e: print(f\"ERRO NA GERAÇÃO DE CHAVES: {e}, DADOS: {row}\")\n",
    "        if resultados: yield pd.DataFrame(resultados)\n",
    "\n",
    "def _gerar_chaves_pix(df_contas_completo: DataFrame, df_clientes_completo: DataFrame, estado_ibge: int, municipio_ibge: int) -> DataFrame:\n",
    "    df_contas_com_cliente = df_contas_completo.join(df_clientes_completo, df_contas_completo.id_cliente == df_clientes_completo.id, \"inner\").select(df_contas_completo.id.alias(\"id_conta\"), \"id_natureza\", \"registro_nacional\", \"aberta_em\", df_contas_completo.is_high_risk)\n",
    "    gerador_com_contexto = functools.partial(_gerar_detalhes_chave_udf, config=config_geracao)\n",
    "    return (df_contas_com_cliente.mapInPandas(gerador_com_contexto, schema=SCHEMA_CHAVES_UDF)\n",
    "            .withColumn(\"estado_ibge\", F.lit(estado_ibge)).withColumn(\"municipio_ibge\", F.lit(municipio_ibge)))\n",
    "\n",
    "# --- Funções de Geração de Transações (com Lógica Avançada de Fraude) ---\n",
    "def _obter_params_tempo(ano: int, mes: int) -> tuple:\n",
    "    num_dias = calendar.monthrange(ano, mes)[1]; primeiro_dia = datetime(ano, mes, 1)\n",
    "    ultimo_dia = datetime(ano, mes, num_dias, 23, 59, 59)\n",
    "    return primeiro_dia, (ultimo_dia - primeiro_dia).total_seconds()\n",
    "\n",
    "def _aplicar_horario_suspeito(data_transacao, config):\n",
    "    if random.random() < config.get('PROBABILIDADE_ATAQUE_MADRUGADA', 0.70):\n",
    "        return data_transacao.replace(hour=random.randint(1, 4), minute=random.randint(0, 59))\n",
    "    return data_transacao\n",
    "\n",
    "def _gerar_detalhes_transacao_python_vetorizado(iterator: Iterator[pd.DataFrame], ano: int, mes: int, config: dict, perfis_uso: list) -> Iterator[pd.DataFrame]:\n",
    "    primeiro_dia, delta_segundos = _obter_params_tempo(ano, mes)\n",
    "    colunas_finais_transacoes = [\"id\", \"valor\", \"data\", \"mensagem\", \"id_conta_origem\", \"id_conta_destino\", \"id_tipo_iniciacao_pix\", \"id_finalidade_pix\", \"is_fraud\", \"fraud_type\", \"id_transacao_cadeia_pai\"]\n",
    "    PROBS_PROFUNDIDADE = [0.35, 0.60, 0.05]; PROB_RUIDO = 0.25; MENSAGENS_RUIDO = [\"Pagamento de Boleto\", \"Lanchonete\", \"Uber\", \"Recarga de Celular\"]\n",
    "    for lote in iterator:\n",
    "        n = len(lote)\n",
    "        if n == 0: continue\n",
    "        lote['data'] = primeiro_dia + pd.to_timedelta(np.random.uniform(0, delta_segundos, n), unit='s')\n",
    "        lote['chave_destino_cadastrada_em'] = pd.to_datetime(lote['chave_destino_cadastrada_em']); delta_dias = (lote['data'] - lote['chave_destino_cadastrada_em']).dt.days\n",
    "        lote['is_high_risk'] = lote['is_high_risk'].fillna(0).astype(int)\n",
    "        prob_fraude_dinamica = np.select([lote['is_high_risk'] == 1, (delta_dias >= 0) & (delta_dias <= config['DIAS_CHAVE_CONSIDERADA_RECENTE'])], [config['PROBABILIDADE_FRAUDE_CONTA_DESTINO_RISCO'], config['PROBABILIDADE_FRAUDE_CHAVE_RECENTE']], default=config['PROBABILIDADE_FRAUDE_BASE'])\n",
    "        lote['is_fraud'] = (np.random.rand(n) < prob_fraude_dinamica).astype(int)\n",
    "        multiplicadores = np.select([lote['is_fraud'] == 1, (~(lote['is_fraud'] == 1)) & (np.random.rand(n) < 0.04)], [config['MULTIPLICADOR_MAGNITUDE_FRAUDE'], 2.5], default=1.0)\n",
    "        valores_calculados = np.maximum(0.01, np.random.lognormal(mean=np.log(150), sigma=0.8, size=n) * multiplicadores).round(2)\n",
    "        condicao_abaixo_radar = (lote['is_fraud'] == 1) & (np.random.rand(n) < config.get('PROBABILIDADE_ABAIXO_RADAR', 0.4))\n",
    "        lote['valor'] = np.where(condicao_abaixo_radar, np.random.choice(config.get('VALORES_LIMITE_RADAR', [999.90]), n), valores_calculados)\n",
    "        probs_tipo_fraude = config.get('PROBABILIDADES_TIPO_FRAUDE'); tipos_fraude = np.random.choice(list(probs_tipo_fraude.keys()), n, p=list(probs_tipo_fraude.values()))\n",
    "        lote['fraud_type'] = np.where(lote['is_fraud'] == 1, tipos_fraude, None)\n",
    "        lote['id'] = [str(uuid.uuid4()) for _ in range(n)]; lote['mensagem'] = \"Pagamento via Pix\"; lote['id_tipo_iniciacao_pix'] = np.random.randint(1, 4, n); lote['id_finalidade_pix'] = np.random.randint(1, 5, n); lote['id_transacao_cadeia_pai'] = None\n",
    "        lote_final = lote.drop(columns=[col for col in ['chave_destino_cadastrada_em', 'is_high_risk', 'id_tipo_conta_origem', 'id_tipo_conta_destino'] if col in lote.columns])\n",
    "        resultados_finais = []\n",
    "        for row in lote_final.itertuples(index=False):\n",
    "            if hasattr(row, 'is_fraud') and row.is_fraud and row.fraud_type in [\"triangulacao_conta_laranja\", \"ataque_de_frequencia\"]:\n",
    "                if random.random() < config.get('PROBABILIDADE_TESTE_CONTA', 0.3):\n",
    "                    resultados_finais.append({\"id\": str(uuid.uuid4()), \"valor\": round(random.uniform(0.01, 1.00), 2), \"data\": row.data - timedelta(minutes=random.randint(1, 5)), \"mensagem\": \"Teste\", \"id_conta_origem\": row.id_conta_origem, \"id_conta_destino\": row.id_conta_destino, \"id_tipo_iniciacao_pix\": 1, \"id_finalidade_pix\": 1, \"is_fraud\": 0, \"fraud_type\": None, \"id_transacao_cadeia_pai\": None})\n",
    "                row_dict = row._asdict(); row_dict['data'] = _aplicar_horario_suspeito(row_dict['data'], config)\n",
    "                profundidade_alvo = np.random.choice([2, 3, 4], p=PROBS_PROFUNDIDADE)\n",
    "                id_fraude_raiz = row_dict['id']; resultados_finais.append(row_dict)\n",
    "                contas_nivel_anterior = {row_dict['id_conta_destino']: row_dict['valor']}; id_pai_nivel_anterior = {row_dict['id_conta_destino']: id_fraude_raiz}; data_nivel_anterior = {row_dict['id_conta_destino']: row_dict['data']}\n",
    "                for nivel_atual in range(2, profundidade_alvo + 1):\n",
    "                    contas_proximo_nivel = {}; id_pai_proximo_nivel = {}; data_proximo_nivel = {}\n",
    "                    if not contas_nivel_anterior: break\n",
    "                    for conta_origem, valor_origem in contas_nivel_anterior.items():\n",
    "                        num_subs = random.randint(2, 7); valores_divididos = np.random.dirichlet(np.ones(num_subs)) * valor_origem\n",
    "                        for k in range(num_subs):\n",
    "                            id_transacao_filha = str(uuid.uuid4()); id_conta_destino_filha = str(uuid.uuid4()); segundos_offset = random.uniform(60 * (nivel_atual-1), 3600 * (nivel_atual-1))\n",
    "                            data_transacao_filha = data_nivel_anterior[conta_origem] + timedelta(seconds=segundos_offset); data_transacao_filha = _aplicar_horario_suspeito(data_transacao_filha, config)\n",
    "                            transacao_filha = {\"id\": id_transacao_filha, \"valor\": round(max(0.01, valores_divididos[k]), 2), \"data\": data_transacao_filha, \"mensagem\": f\"Dispersão N{nivel_atual} (Parte {k+1}/{num_subs})\", \"id_conta_origem\": conta_origem, \"id_conta_destino\": id_conta_destino_filha, \"id_tipo_iniciacao_pix\": random.randint(1, 3), \"id_finalidade_pix\": random.randint(1, 4), \"is_fraud\": 1, \"fraud_type\": row.fraud_type, \"id_transacao_cadeia_pai\": id_pai_nivel_anterior[conta_origem]}\n",
    "                            resultados_finais.append(transacao_filha)\n",
    "                            contas_proximo_nivel[id_conta_destino_filha] = transacao_filha[\"valor\"]; id_pai_proximo_nivel[id_conta_destino_filha] = id_transacao_filha; data_proximo_nivel[id_conta_destino_filha] = data_transacao_filha\n",
    "                            if random.random() < PROB_RUIDO:\n",
    "                                for _ in range(random.randint(1, 3)):\n",
    "                                    segundos_offset_ruido = random.uniform(10, 3600)\n",
    "                                    resultados_finais.append({\"id\": str(uuid.uuid4()), \"valor\": round(random.uniform(7.5, 75.0), 2), \"data\": data_transacao_filha + timedelta(seconds=segundos_offset_ruido), \"mensagem\": random.choice(MENSAGENS_RUIDO), \"id_conta_origem\": id_conta_destino_filha, \"id_conta_destino\": str(uuid.uuid4()), \"id_tipo_iniciacao_pix\": 1, \"id_finalidade_pix\": 1, \"is_fraud\": 0, \"fraud_type\": None, \"id_transacao_cadeia_pai\": None})\n",
    "                    contas_nivel_anterior = contas_proximo_nivel; id_pai_nivel_anterior = id_pai_proximo_nivel; data_nivel_anterior = data_proximo_nivel\n",
    "            else: resultados_finais.append(row._asdict())\n",
    "        if resultados_finais: df_final = pd.DataFrame(resultados_finais); yield df_final[colunas_finais_transacoes]\n",
    "\n",
    "def gerar_transacoes(\n",
    "    df_contas_local: DataFrame, df_chaves_recentes_local: DataFrame, num_contas_local: int,\n",
    "    volume_total: int, estado_ibge: int, municipio_ibge: int, ano: int, mes: int, \n",
    "    municipios_processados: list\n",
    ") -> DataFrame:\n",
    "    \n",
    "    volume_intermunicipal = int(volume_total * PROBABILIDADE_TRANSACAO_INTERMUNICIPAL); volume_local = volume_total - volume_intermunicipal\n",
    "    df_pares_locais = spark.createDataFrame([], SCHEMA_PARES); df_pares_intermunicipais = spark.createDataFrame([], SCHEMA_PARES)\n",
    "    if volume_local > 0 and num_contas_local > 1:\n",
    "        contas_ids_locais = df_contas_local.select(\"id\"); num_contas_locais = num_contas_local\n",
    "        df_pares_indices_locais = spark.range(volume_local).repartition(100).withColumn(\"idx_origem\", (F.rand() * num_contas_locais).cast(\"long\")).withColumn(\"idx_destino\", (F.rand() * num_contas_locais).cast(\"long\")).filter(\"idx_origem != idx_destino\")\n",
    "        contas_numeradas_locais = contas_ids_locais.withColumn(\"idx\", F.row_number().over(Window.orderBy(\"id\")) - 1)\n",
    "        df_pares_locais = df_pares_indices_locais.join(contas_numeradas_locais.alias(\"orig\"), df_pares_indices_locais.idx_origem == F.col(\"orig.idx\")).join(contas_numeradas_locais.alias(\"dest\"), df_pares_indices_locais.idx_destino == F.col(\"dest.idx\")).select(F.col(\"orig.id\").alias(\"id_conta_origem\"), F.col(\"dest.id\").alias(\"id_conta_destino\"))\n",
    "    outros_municipios = [m for m in municipios_processados if m != municipio_ibge]\n",
    "    if volume_intermunicipal > 0 and outros_municipios:\n",
    "        municipio_alvo = random.choice(outros_municipios)\n",
    "        contas_origem = df_contas_local.select(\"id\").orderBy(F.rand()).limit(volume_intermunicipal).withColumnRenamed(\"id\", \"id_conta_origem\").withColumn(\"join_key\", F.monotonically_increasing_id())\n",
    "        contas_destino_externas = spark.table(\"transacoes_db.copper.contas\").filter(F.col(\"municipio_ibge\") == municipio_alvo).select(\"id\").orderBy(F.rand()).limit(volume_intermunicipal).withColumnRenamed(\"id\", \"id_conta_destino\").withColumn(\"join_key\", F.monotonically_increasing_id())\n",
    "        df_pares_intermunicipais = contas_origem.join(contas_destino_externas, \"join_key\").select(\"id_conta_origem\", \"id_conta_destino\")\n",
    "    df_pares_total = df_pares_locais.union(df_pares_intermunicipais)\n",
    "    if df_pares_total.isEmpty(): return spark.createDataFrame([], SCHEMA_TRANSACOES_FINAL)\n",
    "    df_pares_enriquecidos = (df_pares_total\n",
    "        .join(df_contas_local.alias(\"orig\"), df_pares_total.id_conta_origem == F.col(\"orig.id\"), \"left\")\n",
    "        .join(df_contas_local.alias(\"dest\"), df_pares_total.id_conta_destino == F.col(\"dest.id\"), \"left\")\n",
    "        .join(df_chaves_recentes_local.alias(\"chaves\"), df_pares_total.id_conta_destino == F.col(\"chaves.id_conta\"), \"left\")\n",
    "        .select(\"id_conta_origem\", \"id_conta_destino\", F.col(\"orig.id_tipo_conta\").alias(\"id_tipo_conta_origem\"),\n",
    "                F.col(\"dest.id_tipo_conta\").alias(\"id_tipo_conta_destino\"), F.col(\"chaves.chave_destino_cadastrada_em\"), F.col(\"dest.is_high_risk\")))\n",
    "    gerador_com_contexto = functools.partial(_gerar_detalhes_transacao_python_vetorizado, ano=ano, mes=mes, config=config_geracao, perfis_uso=perfis_de_uso_dict)\n",
    "    df_transacoes_bruto = df_pares_enriquecidos.mapInPandas(gerador_com_contexto, schema=SCHEMA_TRANSACOES_UDF)\n",
    "    return df_transacoes_bruto.withColumn(\"estado_ibge\", F.lit(estado_ibge))\n",
    "\n",
    "# --- Funções Utilitárias e de Orquestração ---\n",
    "def salvar_dataframe_em_delta(df: DataFrame, nome_tabela_completo: str, modo: str = \"append\"):\n",
    "    if df is None or df.isEmpty(): print(f\"AVISO: DataFrame para a tabela '{nome_tabela_completo}' está vazio. Nenhuma ação tomada.\"); return\n",
    "    try:\n",
    "        print(f\"INFO: Salvando dados na tabela Delta: {nome_tabela_completo} (modo: {modo})...\"); df.write.format(\"delta\").mode(modo).saveAsTable(nome_tabela_completo)\n",
    "        print(f\"✅ SUCESSO: Dados salvos em {nome_tabela_completo}.\")\n",
    "    except Exception as e: print(f\"❌ ERRO ao salvar '{nome_tabela_completo}': {e}\"); raise e\n",
    "\n",
    "def gerar_e_salvar_populacao(num_pf: int, num_pj: int, estado_ibge: int, municipio_ibge: int) -> DataFrame:\n",
    "    print(f\"INFO: Gerando e materializando população para {municipio_ibge} (PF: {num_pf}, PJ: {num_pj})...\")\n",
    "    df_clientes_gerado = _gerar_clientes(num_pf, num_pj, estado_ibge, municipio_ibge); salvar_dataframe_em_delta(df_clientes_gerado, \"transacoes_db.copper.clientes\", modo=\"append\")\n",
    "    df_clientes_materializado = spark.table(\"transacoes_db.copper.clientes\").filter(F.col(\"municipio_ibge\") == municipio_ibge)\n",
    "    df_contas_gerado = _gerar_contas(df_clientes_materializado, estado_ibge, municipio_ibge)\n",
    "    salvar_dataframe_em_delta(df_contas_gerado, \"transacoes_db.copper.contas\", modo=\"append\")\n",
    "    df_contas_materializado = spark.table(\"transacoes_db.copper.contas\").filter(F.col(\"municipio_ibge\") == municipio_ibge)\n",
    "    df_chaves_pix = _gerar_chaves_pix(df_contas_materializado, df_clientes_materializado, estado_ibge, municipio_ibge); salvar_dataframe_em_delta(df_chaves_pix, \"transacoes_db.copper.chaves_pix\", modo=\"append\")\n",
    "    print(f\"INFO: População para o município {municipio_ibge} adicionada com sucesso.\")\n",
    "    return df_contas_materializado\n",
    "\n",
    "def limpar_tabelas_de_destino():\n",
    "    print(\"INFO: Apagando tabelas de destino para recriação...\")\n",
    "    for tabela in [\"clientes\", \"contas\", \"chaves_pix\", \"transacoes\"]: spark.sql(f\"DROP TABLE IF EXISTS transacoes_db.copper.{tabela}\")\n",
    "    print(\"INFO: ✅ Limpeza concluída.\")\n",
    "\n",
    "def criar_tabelas_de_destino():\n",
    "    print(\"INFO: Criando tabelas de destino com os schemas corretos...\")\n",
    "    tabelas = {\"transacoes_db.copper.clientes\": (SCHEMA_CLIENTES_FINAL, [\"estado_ibge\", \"municipio_ibge\"]),\n",
    "               \"transacoes_db.copper.contas\": (SCHEMA_CONTAS_FINAL, [\"estado_ibge\", \"municipio_ibge\"]),\n",
    "               \"transacoes_db.copper.chaves_pix\": (SCHEMA_CHAVES_PIX_FINAL, [\"estado_ibge\", \"municipio_ibge\"]),\n",
    "               \"transacoes_db.copper.transacoes\": (SCHEMA_TRANSACOES_FINAL, [\"estado_ibge\"])}\n",
    "    for nome, (schema, part_cols) in tabelas.items():\n",
    "        spark.createDataFrame([], schema).write.format(\"delta\").partitionBy(part_cols).mode(\"overwrite\").saveAsTable(nome)\n",
    "        print(f\"INFO: Tabela '{nome}' criada com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e595ad3f-94b3-4f34-92ce-7ccb468eb772",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Modelagem Matemática para Simulação de Dados Sintéticos\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introdução\n",
    "\n",
    "Este documento detalha a modelagem matemática e estatística utilizada para gerar uma população e um volume de transações sintéticas que refletem o comportamento e as características de um ambiente financeiro real, em conformidade com dados estatísticos regionais (perfis de uso) e regras de negócio.\n",
    "\n",
    "A modelagem se divide em três etapas principais:\n",
    "\n",
    "1. **Dimensionamento do volume**\n",
    "2. **Dimensionamento da população**\n",
    "3. **Modelagem comportamental para a geração de transações**\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Dimensionamento do Volume de Transações\n",
    "\n",
    "O volume total de transações a ser gerado para o município é baseado em dados estatísticos conhecidos (média mensal de transações) e ajustado ao escopo da simulação por meio de um fator de amostragem.\n",
    "\n",
    "### 2.1. Fórmula do Volume Anual\n",
    "\n",
    "O volume total anual de transações a gerar ($V_{\\text{ano}}$) é calculado pela seguinte relação:\n",
    "\n",
    "$$\n",
    "V_{\\text{ano}} = (\\overline{T}_{\\text{mensal}} \\times 12) \\times P_{\\text{amostra}}\n",
    "$$\n",
    "\n",
    "| Termo                | Definição                                                                                  |\n",
    "|----------------------|-------------------------------------------------------------------------------------------|\n",
    "| $V_{\\text{ano}}$     | Volume anual total de transações a ser gerado.                                            |\n",
    "| $\\overline{T}_{\\text{mensal}}$ | Média estatística do número de transações de pagadores por mês no município.         |\n",
    "| $P_{\\text{amostra}}$ | Percentual da amostra desejada (`DATA_SAMPLE_PERCENTAGE`), fração do dado real a simular. |\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Dimensionamento da População Sintética\n",
    "\n",
    "Com o volume de transações definido, é necessário estimar o número de clientes que compõem a população sintética, garantindo que o volume transacional seja distribuído de forma crível.\n",
    "\n",
    "### 3.1. Cálculo do Número Total de Clientes\n",
    "\n",
    "O número total de clientes a serem gerados ($N_{\\text{clientes}}$) é estimado a partir da média mensal de transações, ajustado por um fator de escala de população ($F_{\\text{escala}}$) e o percentual da amostra:\n",
    "\n",
    "$$\n",
    "N_{\\text{clientes}} = \\left\\lfloor \\frac{\\overline{T}_{\\text{mensal}}}{F_{\\text{escala}}} \\times P_{\\text{amostra}} \\right\\rfloor\n",
    "$$\n",
    "\n",
    "| Termo             | Definição                                                                                      |\n",
    "|-------------------|-----------------------------------------------------------------------------------------------|\n",
    "| $N_{\\text{clientes}}$ | Número total de clientes (Pessoa Física e Jurídica) a gerar.                                  |\n",
    "| $F_{\\text{escala}}$   | Fator de escala para relacionar volume transacional com número de clientes (`POPULATION_SCALING_FACTOR`). |\n",
    "\n",
    "### 3.2. Distribuição por Natureza (Pessoa Física e Jurídica)\n",
    "\n",
    "O total de clientes é dividido em Pessoa Física ($N_{\\text{PF}}$) e Pessoa Jurídica ($N_{\\text{PJ}}$) com base na proporção observada de transações de Pessoa Física ($\\%_{\\text{PF}}$) no município:\n",
    "\n",
    "$$\n",
    "N_{\\text{PF}} = \\lfloor N_{\\text{clientes}} \\times \\%_{\\text{PF}} \\rfloor\n",
    "$$\n",
    "\n",
    "$$\n",
    "N_{\\text{PJ}} = N_{\\text{clientes}} - N_{\\text{PF}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Modelagem Comportamental e Geração de Transações\n",
    "\n",
    "Esta seção detalha os modelos estatísticos e as regras condicionais utilizadas para gerar as transações individuais (valores, datas e características de fraude).\n",
    "\n",
    "### 4.1. Distribuição Proporcional por Perfil\n",
    "\n",
    "Para garantir que a \"mistura\" de tipos de transação no município sintético reflita a região, o volume total é distribuído proporcionalmente aos perfis de uso definidos.\n",
    "\n",
    "Primeiro, calcula-se o peso ($W_i$) de cada Perfil $i$:\n",
    "\n",
    "$$\n",
    "W_i = \\frac{Q_i}{\\sum_{j=1}^{P} Q_j}\n",
    "$$\n",
    "\n",
    "Onde $Q_i$ é a quantidade de transações do Perfil $i$ e $\\sum_{j=1}^{P} Q_j$ é a soma das quantidades de todos os perfis ($P$).\n",
    "\n",
    "Em seguida, calcula-se o volume de transações específicas para o Perfil $i$ ($V_i$):\n",
    "\n",
    "$$\n",
    "V_i = \\lfloor V_{\\text{ano}} \\times W_i \\rfloor\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 4.2. Modelagem de Valores Monetários (Distribuição Log-Normal)\n",
    "\n",
    "A **Distribuição Log-Normal** é empregada para modelar valores monetários (saldos e valores de transação) devido à sua assimetria e natureza não negativa, o que se alinha ao comportamento de dados financeiros.\n",
    "\n",
    "Os parâmetros $\\hat{\\mu}$ (média do logaritmo) e $\\hat{\\sigma}$ (desvio padrão do logaritmo) são estimados a partir de estatísticas robustas (mediana e quartis) dos perfis para calibrar a geração:\n",
    "\n",
    "$$\n",
    "\\hat{\\mu} = \\ln(\\text{Mediana})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma} = \\frac{\\ln(P_{75}) - \\ln(P_{25})}{1.349}\n",
    "$$\n",
    "\n",
    "O valor final da transação ($X$) é gerado a partir desta distribuição, onde o valor base é multiplicado por fatores de ajuste para simular fraudes ou valores outliers.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.3. Simulação de Eventos (Ensaio de Bernoulli e Lógica Condicional)\n",
    "\n",
    "#### A. Ensaio de Bernoulli\n",
    "\n",
    "A ocorrência de eventos discretos, como a marcação de uma transação como fraude, é modelada como um **Ensaio de Bernoulli**, onde a variável aleatória binária $X$ (sucesso/fracasso) é determinada por um número aleatório $U \\sim \\text{Uniforme}(0, 1)$ e uma probabilidade dinâmica $p$:\n",
    "\n",
    "$$\n",
    "X =\n",
    "\\begin{cases}\n",
    "1, & \\text{se } U < p \\ (\\text{sucesso/fraude}) \\\\\n",
    "0, & \\text{se } U \\geq p \\ (\\text{falha/normal})\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "#### B. Lógica Condicional Vetorizada (`np.select`)\n",
    "\n",
    "A probabilidade de fraude ($P_{\\text{fraude}}$), que define o parâmetro $p$ do Ensaio de Bernoulli, é calculada em função de múltiplas regras de negócio e características da transação (vetorizada pelo `np.select`), como demonstrado no exemplo:\n",
    "\n",
    "$$\n",
    "P_{\\text{fraude}} =\n",
    "\\begin{cases}\n",
    "P_1, & \\text{se a conta destino é de alto risco} \\\\\n",
    "P_2, & \\text{se } \\Delta_{\\text{dias}} \\leq D_{\\text{recente}} \\text{ (chave recente)} \\\\\n",
    "P_3, & \\text{caso contrário}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 4.4. Simulação de Cadeias de Lavagem (Distribuição de Dirichlet)\n",
    "\n",
    "Em cenários de fraude complexa (e.g., triangulação), a **Distribuição de Dirichlet** é utilizada para simular a pulverização de um valor total em $N$ sub-transações aleatórias, garantindo que a soma das proporções seja igual a 1.\n",
    "\n",
    "O vetor de proporções $\\vec{x} = (x_1, \\dots, x_N)$ é gerado com base em parâmetros de concentração $\\alpha_i$ (tipicamente uniformes, $\\alpha_i = 1$) e aplicado ao valor da transação raiz: $V_i = x_i \\cdot V_{\\text{raiz}}$\n",
    "\n",
    "$$\n",
    "(x_1, \\dots, x_N) \\sim \\mathrm{Dirichlet}(\\alpha_1, \\dots, \\alpha_N)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^N x_i = 1\n",
    "$$\n",
    "\n",
    "O valor de cada sub-transação $V_i$ é dado por:\n",
    "\n",
    "$$\n",
    "V_i = x_i \\cdot V_{\\text{raiz}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Conclusão\n",
    "\n",
    "A integração da **Distribuição Log-Normal**, do **Ensaio de Bernoulli**, da **Lógica Condicional Vetorizada** e da **Distribuição de Dirichlet** permite que o script de geração simule de forma eficaz um ecossistema financeiro robusto, com comportamentos e patamares de risco que se assemelham aos dados reais.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4311c855-863d-4608-a3fe-c707e29a7e66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 4: ORQUESTRAÇÃO E EXECUÇÃO PRINCIPAL (VERSÃO FINAL OTIMIZADA)\n",
    "# =============================================================================\n",
    "try:\n",
    "    limpar_tabelas_de_destino()\n",
    "    criar_tabelas_de_destino()\n",
    "    print(\"=============================================================================\")\n",
    "    print(f\"INFO: Iniciando processo de geração ANUAL (Ano: {ANO_ESTATISTICA})...\")\n",
    "    \n",
    "    print(\"INFO: Lendo volumes anuais da tabela agregada...\")\n",
    "    df_volumes_anuais = spark.table(\"transacoes_db.pix_baseline_metricas.volumes_anuais_por_municipio\").filter(F.col(\"Ano\") == ANO_ESTATISTICA)\n",
    "    \n",
    "    print(\"INFO: Rankeando municípios para seleção...\")\n",
    "    df_ranks_anuais = df_volumes_anuais.withColumn(\"rank_pagador_anual\", F.rank().over(Window.orderBy(F.col(\"volume_pagador_anual\").desc())))\n",
    "    \n",
    "    municipios_a_processar_lista = df_ranks_anuais.orderBy(F.col(\"rank_pagador_anual\").asc()).limit(LIMITE_MUNICIPIOS_PROCESSADOS).collect()\n",
    "    total_municipios = len(municipios_a_processar_lista)\n",
    "    print(f\"INFO: {total_municipios} municípios selecionados para processar.\")\n",
    "    \n",
    "    id_municipios_selecionados = [row[\"cod_ibge_municipio\"] for row in municipios_a_processar_lista]\n",
    "\n",
    "    print(\"INFO: Coletando estatísticas mensais para os municípios selecionados...\")\n",
    "    stats_mensal_pd = (spark.table(\"transacoes_db.pix_baseline_metricas.relacao_pagadores_recebedores\")\n",
    "                       .filter((F.col(\"ano\") == ANO_ESTATISTICA) & (F.col(\"Municipio_Ibge\").isin(id_municipios_selecionados)))\n",
    "                       .select(\"Municipio_Ibge\", \"Mes\", \"total_tx_pf_pagador\", \"total_tx_pj_pagador\").toPandas())\n",
    "    stats_mensal_pd['total_tx_pagador'] = stats_mensal_pd['total_tx_pf_pagador'] + stats_mensal_pd['total_tx_pj_pagador']\n",
    "    print(\"INFO: Estatísticas mensais coletadas com sucesso.\")\n",
    "\n",
    "    municipios_ja_processados = []\n",
    "\n",
    "    for i, municipio_row in enumerate(municipios_a_processar_lista):\n",
    "        codigo_municipio = municipio_row[\"cod_ibge_municipio\"]\n",
    "        codigo_estado = municipio_row[\"cod_ibge_estado\"]\n",
    "        nome_municipio = municipio_row[\"municipio_nome\"]\n",
    "        \n",
    "        print(f\"\\n================== Processando Município {i+1}/{total_municipios}: {nome_municipio} ({codigo_municipio}) ==================\")\n",
    "        \n",
    "        fator_escala_final = FATOR_ESCALA_VOLUME\n",
    "        print(f\"INFO: Fator de escala para {nome_municipio}: {fator_escala_final:.8f}\")\n",
    "\n",
    "        volume_pf_anual = int(municipio_row[\"total_pf_anual\"] * fator_escala_final)\n",
    "        volume_pj_anual = int(municipio_row[\"total_pj_anual\"] * fator_escala_final)\n",
    "        num_pf = max(1, int(volume_pf_anual / (TX_POR_CLIENTE_ESPERADO * 12)))\n",
    "        num_pj = max(1, int(volume_pj_anual / (TX_POR_CLIENTE_ESPERADO * 12)))\n",
    "\n",
    "        df_contas_do_municipio = gerar_e_salvar_populacao(num_pf=num_pf, num_pj=num_pj, estado_ibge=codigo_estado, municipio_ibge=codigo_municipio)\n",
    "        municipios_ja_processados.append(codigo_municipio)\n",
    "\n",
    "        # --- AJUSTE FINAL: PREPARAÇÃO DOS DADOS FEITA UMA VEZ POR MUNICÍPIO ---\n",
    "        print(\"INFO: Preparando dados do município para o loop mensal (executado uma vez)...\")\n",
    "        num_contas_do_municipio = df_contas_do_municipio.count()\n",
    "        \n",
    "        df_chaves_do_municipio = spark.table(\"transacoes_db.copper.chaves_pix\").filter(F.col(\"municipio_ibge\") == codigo_municipio)\n",
    "        window_chaves = Window.partitionBy(\"id_conta\").orderBy(F.col(\"cadastrada_em\").desc())\n",
    "        df_chaves_recentes_do_municipio = (df_chaves_do_municipio.withColumn(\"rank\", F.rank().over(window_chaves))\n",
    "                                           .filter(F.col(\"rank\") == 1).select(\"id_conta\", F.col(\"cadastrada_em\").alias(\"chave_destino_cadastrada_em\")))\n",
    "\n",
    "        for mes in range(1, 13):\n",
    "            print(f\"\\n--- Processando Mês {mes}/{ANO_ESTATISTICA} para {nome_municipio} ---\")\n",
    "            \n",
    "            stats_mensal = stats_mensal_pd[(stats_mensal_pd['Municipio_Ibge'] == codigo_municipio) & (stats_mensal_pd['Mes'] == mes)]\n",
    "            if stats_mensal.empty: print(f\"AVISO: Sem estatísticas para {mes}/{ANO_ESTATISTICA}. Pulando.\"); continue\n",
    "            \n",
    "            volume_total_original = stats_mensal[\"total_tx_pagador\"].iloc[0]\n",
    "            volume_total = int(volume_total_original * fator_escala_final)\n",
    "            if volume_total <= 0: print(f\"AVISO: Volume de transações base para {mes}/{ANO_ESTATISTICA} é 0 ou negativo. Pulando.\"); continue\n",
    "                \n",
    "            print(f\"      Volume Original: {volume_total_original} | Volume BASE Alvo: {volume_total}\")\n",
    "            \n",
    "            df_transacoes = gerar_transacoes(\n",
    "                df_contas_local=df_contas_do_municipio,\n",
    "                df_chaves_recentes_local=df_chaves_recentes_do_municipio,\n",
    "                num_contas_local=num_contas_do_municipio,\n",
    "                volume_total=volume_total, estado_ibge=codigo_estado, municipio_ibge=codigo_municipio,\n",
    "                ano=ANO_ESTATISTICA, mes=mes, municipios_processados=municipios_ja_processados\n",
    "            )\n",
    "            salvar_dataframe_em_delta(df_transacoes, \"transacoes_db.copper.transacoes\", modo=\"append\")\n",
    "finally:\n",
    "    print(\"\\nINFO: O script chegou ao fim.\")\n",
    "\n",
    "print(\"\\n=============================================================================\")\n",
    "print(\"INFO: Processo de geração de dados sintéticos concluído.\")\n",
    "print(\"=============================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2d1de55-4f3c-44ad-a1b1-1d3fc425bf65",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1761099536969}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TABLE transacoes_db.gold.transacoes_dataset\n",
    "SELECT\n",
    "  -- Colunas da transação\n",
    "  tx.id AS transacao_id,\n",
    "  tx.valor AS valor_transacao,\n",
    "  tx.data AS data_transacao,\n",
    "  tx.mensagem AS mensagem_pix,\n",
    "  tx.id_conta_origem AS id_conta_pagador,\n",
    "  tx.id_conta_destino AS id_conta_recebedor,\n",
    "  tx.id_tipo_iniciacao_pix AS tipo_iniciacao_pix_id,\n",
    "  tx.id_finalidade_pix AS finalidade_pix_id,\n",
    "  tx.is_fraud AS transacao_fraudulenta,\n",
    "  tx.fraud_type AS tipo_fraude,\n",
    "  tx.id_transacao_cadeia_pai AS id_transacao_cadeia_pai,\n",
    "  tx.estado_ibge AS estado_ibge_transacao,\n",
    "\n",
    "  -- Pagador: Conta\n",
    "  conta_orig.id AS pagador_conta_id,\n",
    "  conta_orig.saldo AS pagador_saldo,\n",
    "  conta_orig.aberta_em AS pagador_conta_aberta_em,\n",
    "  conta_orig.agencia AS pagador_agencia,\n",
    "  conta_orig.numero AS pagador_numero_conta,\n",
    "  conta_orig.id_tipo_conta AS pagador_tipo_conta_id,\n",
    "  conta_orig.ispb_instituicao AS pagador_ispb_instituicao,\n",
    "  conta_orig.id_cliente AS pagador_cliente_id_conta,\n",
    "  conta_orig.is_high_risk AS pagador_conta_alto_risco,\n",
    "  conta_orig.estado_ibge AS pagador_estado_ibge,\n",
    "  conta_orig.municipio_ibge AS pagador_municipio_ibge,\n",
    "\n",
    "  -- Pagador: Cliente\n",
    "  cliente_orig.id AS pagador_cliente_id,\n",
    "  cliente_orig.nome AS pagador_nome,\n",
    "  cliente_orig.id_natureza AS pagador_natureza_id,\n",
    "  cliente_orig.registro_nacional AS pagador_registro_nacional,\n",
    "  cliente_orig.nascido_em AS pagador_data_nascimento,\n",
    "  cliente_orig.estado_ibge AS pagador_estado_ibge_cliente,\n",
    "  cliente_orig.municipio_ibge AS pagador_municipio_ibge_cliente,\n",
    "\n",
    "  -- Pagador: Instituição\n",
    "  inst_orig.ispb AS pagador_instituicao_ispb,\n",
    "  inst_orig.nome AS pagador_instituicao,\n",
    "\n",
    "  -- Pagador: Tipo de Conta\n",
    "  tipo_conta_orig.id AS pagador_tipo_conta_id_ref,\n",
    "  tipo_conta_orig.nome AS pagador_tipo_conta_descricao,\n",
    "\n",
    "  -- Pagador: Município\n",
    "  mun_orig.codigo_ibge AS pagador_municipio_ibge_ref,\n",
    "  mun_orig.nome AS pagador_municipio,\n",
    "\n",
    "  -- Pagador: Natureza\n",
    "  natureza_orig.id AS pagador_natureza_id_ref,\n",
    "  natureza_orig.nome AS pagador_natureza,\n",
    "\n",
    "  -- Recebedor: Conta\n",
    "  conta_dest.id AS recebedor_conta_id,\n",
    "  conta_dest.saldo AS recebedor_saldo,\n",
    "  conta_dest.aberta_em AS recebedor_conta_aberta_em,\n",
    "  conta_dest.agencia AS recebedor_agencia,\n",
    "  conta_dest.numero AS recebedor_numero_conta,\n",
    "  conta_dest.id_tipo_conta AS recebedor_tipo_conta_id,\n",
    "  conta_dest.ispb_instituicao AS recebedor_ispb_instituicao,\n",
    "  conta_dest.id_cliente AS recebedor_cliente_id_conta,\n",
    "  conta_dest.is_high_risk AS recebedor_conta_alto_risco,\n",
    "  conta_dest.estado_ibge AS recebedor_estado_ibge,\n",
    "  conta_dest.municipio_ibge AS recebedor_municipio_ibge,\n",
    "\n",
    "  -- Recebedor: Cliente\n",
    "  cliente_dest.id AS recebedor_cliente_id,\n",
    "  cliente_dest.nome AS recebedor_nome,\n",
    "  cliente_dest.id_natureza AS recebedor_natureza_id,\n",
    "  cliente_dest.registro_nacional AS recebedor_registro_nacional,\n",
    "  cliente_dest.nascido_em AS recebedor_data_nascimento,\n",
    "  cliente_dest.estado_ibge AS recebedor_estado_ibge_cliente,\n",
    "  cliente_dest.municipio_ibge AS recebedor_municipio_ibge_cliente,\n",
    "\n",
    "  -- Recebedor: Instituição\n",
    "  inst_dest.ispb AS recebedor_instituicao_ispb,\n",
    "  inst_dest.nome AS recebedor_instituicao,\n",
    "\n",
    "\n",
    "  -- Recebedor: Tipo de Conta\n",
    "  tipo_conta_dest.id AS recebedor_tipo_conta_id_ref,\n",
    "  tipo_conta_dest.nome AS recebedor_tipo_conta_descricao,\n",
    "\n",
    "  -- Recebedor: Município\n",
    "  mun_dest.codigo_ibge AS recebedor_municipio_ibge_ref,\n",
    "  mun_dest.nome AS recebedor_municipio,\n",
    "\n",
    "  -- Recebedor: Natureza\n",
    "  natureza_dest.id AS recebedor_natureza_id_ref,\n",
    "  natureza_dest.nome AS recebedor_natureza\n",
    "\n",
    "\n",
    "FROM\n",
    "  transacoes_db.copper.transacoes AS tx\n",
    "\n",
    "LEFT JOIN transacoes_db.copper.contas AS conta_orig\n",
    "  ON tx.id_conta_origem = conta_orig.id\n",
    "LEFT JOIN transacoes_db.copper.clientes AS cliente_orig\n",
    "  ON conta_orig.id_cliente = cliente_orig.id\n",
    "LEFT JOIN transacoes_db.copper.instituicoes AS inst_orig\n",
    "  ON conta_orig.ispb_instituicao = inst_orig.ispb\n",
    "LEFT JOIN transacoes_db.copper.tipos_conta AS tipo_conta_orig\n",
    "  ON conta_orig.id_tipo_conta = tipo_conta_orig.id\n",
    "LEFT JOIN transacoes_db.copper.municipios AS mun_orig\n",
    "  ON cliente_orig.municipio_ibge = mun_orig.codigo_ibge\n",
    "LEFT JOIN transacoes_db.copper.naturezas AS natureza_orig\n",
    "  ON cliente_orig.id_natureza = natureza_orig.id\n",
    "\n",
    "LEFT JOIN transacoes_db.copper.contas AS conta_dest\n",
    "  ON tx.id_conta_destino = conta_dest.id\n",
    "LEFT JOIN transacoes_db.copper.clientes AS cliente_dest\n",
    "  ON conta_dest.id_cliente = cliente_dest.id\n",
    "LEFT JOIN transacoes_db.copper.instituicoes AS inst_dest\n",
    "  ON conta_dest.ispb_instituicao = inst_dest.ispb\n",
    "LEFT JOIN transacoes_db.copper.tipos_conta AS tipo_conta_dest\n",
    "  ON conta_dest.id_tipo_conta = tipo_conta_dest.id\n",
    "LEFT JOIN transacoes_db.copper.municipios AS mun_dest\n",
    "  ON cliente_dest.municipio_ibge = mun_dest.codigo_ibge\n",
    "LEFT JOIN transacoes_db.copper.naturezas AS natureza_dest\n",
    "  ON cliente_dest.id_natureza = natureza_dest.id\n",
    "\n",
    "LEFT JOIN transacoes_db.copper.finalidade_pix AS finalidade_pix\n",
    "  ON tx.id_finalidade_pix = finalidade_pix.id\n",
    "\n",
    "ORDER BY\n",
    "  tx.data DESC"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6452701694112093,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "gerador_de_dados",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
